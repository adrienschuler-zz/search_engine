
class Tokenizer:

    def whitespace(doc: str) -> list:
        return doc.split(' ')
